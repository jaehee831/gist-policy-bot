import os
import numpy as np
import faiss
import openai
import time
from dotenv import load_dotenv, find_dotenv
import streamlit as st
from langdetect import detect

# .env íŒŒì¼ ë¡œë“œ
dotenv_path = find_dotenv()
if dotenv_path:
    load_dotenv(dotenv_path)
else:
    raise FileNotFoundError(".env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
api_key = os.getenv('OPENAI_API_KEY')
if api_key is None:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
openai.api_key = api_key

# í˜„ì¬ ë””ë ‰í† ë¦¬ ì„¤ì •
current_dir = os.getcwd()
vector_db_dir = os.path.join(current_dir, '../VectorDB')

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ
index = faiss.read_index(os.path.join(vector_db_dir, 'vector_db.index'))
index_dimension = index.d  # ì¸ë±ìŠ¤ì˜ ì°¨ì› í™•ì¸

# íŒŒì¼ ê²½ë¡œ ë¡œë“œ
with open(os.path.join(vector_db_dir, 'file_paths.txt'), 'r', encoding='utf-8') as f:
    file_paths = [line.strip() for line in f]

# ëª¨ë“  ë¬¸ì„œ ë¡œë“œ
documents = []
for path in file_paths:
    with open(path, 'r', encoding='utf-8') as file:
        documents.append(file.read())

# ì„ë² ë”© ìƒì„± í•¨ìˆ˜
def get_embedding(text):
    response = openai.Embedding.create(
        input=text,
        engine="text-embedding-ada-002"
    )
    return np.array(response['data'][0]['embedding'], dtype=np.float32)

def search(query, top_k=3):
    # ì¿¼ë¦¬ ë²¡í„°í™”
    query_embedding = get_embedding(query).reshape(1, -1)
    
    # ì°¨ì› ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
    if query_embedding.shape[1] != index_dimension:
        raise ValueError(f"Query embedding dimension {query_embedding.shape[1]} does not match index dimension {index_dimension}")

    # FAISS ì¸ë±ìŠ¤ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
    D, I = index.search(query_embedding, top_k)
    
    results = [(file_paths[i], documents[i]) for i in I[0]]
    return results

def generate_answer(query, top_k=2):
    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    relevant_docs = search(query, top_k)
    
    # ê´€ë ¨ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
    context = "\n\n".join(doc for _, doc in relevant_docs)
    references = "\n".join(path for path, _ in relevant_docs)
    
    language = detect(query)

    if language == 'ko':
        system_message = ("ì´ ì±—ë´‡ì€ ê´‘ì£¼ê³¼í•™ê¸°ìˆ ì›(GIST) êµ¬ì„±ì›ë“¤ì˜ ê·œì • ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•˜ê¸° ìœ„í•´ "
                          "ë§Œë“¤ì–´ì§„ ì±—ë´‡ì…ë‹ˆë‹¤. ì±—ë´‡ì€ ë°ì´í„°ë² ì´ìŠ¤ì— ìˆëŠ” ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤. "
                          "ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤: [ì£„ì†¡í•©ë‹ˆë‹¤, ì´ ì •ë³´ëŠ” GIST ê·œì • ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ "
                          "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ë¶€ì„œì— ë¬¸ì˜í•˜ì—¬ ë„ì›€ì„ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤. (GIST ê¸°íšíŒ€ í™©ì¸í˜¸ íŒ€ì¥ 062-715-2971)]ë¼ëŠ” "
                          "ì•ˆë‚´ê°€ í‘œì‹œë©ë‹ˆë‹¤. ë˜í•œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë¶ˆì™„ì „í•œ ê²½ìš° ì±—ë´‡ì€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ ì •ë³´ë¥¼ ìš”ì²­í•´ì•¼ í•©ë‹ˆë‹¤. "
                          "ì˜ˆë¥¼ ë“¤ì–´ 'ë³´ë‹¤ ì •í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ëª‡ ê°€ì§€ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. í•„ìš”í•œ ì¶”ê°€ ì •ë³´]ì™€ ê°™ì€ ì„¸ë¶€ ì •ë³´ë¥¼ "
                          "ì œê³µí•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?")
    else:
        system_message = ("This GPT is a chatbot designed to provide answers to questions related to regulations for members of the Gwangju Institute of Science and Technology (GIST). "
                          "It should respond in a friendly manner. The chatbot will answer questions based on information in the database. If the information is not available in the database, "
                          "it should respond as follows: [Sorry, this information is not available in the GIST regulations database. Please contact the relevant department for assistance. "
                          "(GIST ê¸°íšíŒ€ í™©ì¸í˜¸ íŒ€ì¥ 062-715-2971)] Additionally, if the user's question is incomplete, the chatbot should request additional information based on the database. "
                          "For example: [To provide you with a more accurate answer, I need some additional information. Could you please provide details such as [necessary additional information]?")

    # OpenAI GPT-4 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": f"Here are some documents:\n\n{context}\n\nQuestion: {query}\nAnswer:"}
        ],
        max_tokens=1000  # max_tokens ê°’ì„ ì¦ê°€ì‹œì¼œ ì˜ë¦¬ëŠ” ë¬¸ì œ ë°©ì§€
    )
    
    answer = response.choices[0].message['content'].strip()
    return answer, references

# Streamlit ì•± ì„¤ì •
st.image(r"..\gist.jpg", use_column_width=True)
st.header("ğŸ¤– Gist Policy App (Demo)")

if 'generated' not in st.session_state:
    st.session_state['generated'] = []

if 'past' not in st.session_state:
    st.session_state['past'] = []

with st.form('form', clear_on_submit=True):
    user_input = st.text_input('ì§ˆë¬¸: ', '', key='input')
    submitted = st.form_submit_button('ì „ì†¡')

if submitted and user_input:
    answer, references = generate_answer(user_input)
    st.session_state.past.append(user_input)
    st.session_state.generated.append((answer, references))

if st.session_state['generated']:
    for i in range(len(st.session_state['generated'])-1, -1, -1):
        user_question = st.session_state['past'][i]
        bot_answer, references = st.session_state['generated'][i]
        st.write(f'**ì§ˆë¬¸:** {user_question}')
        st.write(f'**ë‹µë³€:** {bot_answer}')
        st.write(f'**ì°¸ì¡°í•œ ë¬¸ì„œ ê²½ë¡œ:**\n{references}')
